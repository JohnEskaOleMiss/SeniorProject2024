{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import os\n",
        "from time import sleep\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#preprocess Phishing_Email.csv\n",
        "def cleanData(text):\n",
        "  #remove special characters, html tags, \\n, urls, and extra spaces\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  text = re.sub(r'http\\S+|www\\S+|https\\S+', \" \", text, flags=re.MULTILINE)\n",
        "  text = re.sub(r'\\S{15,}', \" \", text)\n",
        "  text = re.sub(r'[^a-zA-Z\\s]', \" \", text)\n",
        "  text = re.sub(r'<.*?>', \" \", text)\n",
        "  text = re.sub(r'\\\\\\n', \" \", text)\n",
        "  text = re.sub(r'\\s+', \" \", text).strip()\n",
        "  text = text.lower()\n",
        "  text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "  return text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Dy5edLhofnC",
        "outputId": "f9b803c6-8e10-4449-fbb4-2afe660ddfa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "import pandas as pd\n",
        "import re\n",
        "from time import sleep\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "#openAI api phishing analysis\n",
        "def openAITest(text):\n",
        "  #get api key\n",
        "  input_file = 'OpenAIAPIKey.json'\n",
        "  with open(input_file, 'r') as file:\n",
        "      data = json.load(file)\n",
        "  key = data['key']\n",
        "\n",
        "  #set up api connection\n",
        "  api_key = key\n",
        "  client = OpenAI(api_key=api_key)\n",
        "\n",
        "  expected = \"\"\n",
        "  email = text\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": f\"Determine if this email is phishing or safe. If an email is phishing respond with a 1, if it is safe respond with a 0.  Do not use any words. Here it is: {email}\"}\n",
        "    ]\n",
        "  )\n",
        "  expected += completion.choices[0].message.content\n",
        "\n",
        "\n",
        "  expectarray = []\n",
        "\n",
        "  for char in expected:\n",
        "      if char == '1':\n",
        "          expectarray.append(1)\n",
        "      elif char == '0':\n",
        "          expectarray.append(0)\n",
        "\n",
        "  return expectarray[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWs5STswiENn",
        "outputId": "4e95a118-f11a-4fd9-8a16-a8af125cb769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "def load_model_and_predict(email_text):\n",
        "    #load the trained model and tokenizer\n",
        "    model = DistilBertForSequenceClassification.from_pretrained('./distilbert-phishing-detection')\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('./distilbert-phishing-detection')\n",
        "\n",
        "    #tokenize the email text\n",
        "    inputs = tokenizer(email_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "    #predict using the model\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    #get the predicted label\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "cMlRimt9n0-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snsg68aKlPW8"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import metrics\n",
        "\n",
        "def votingModel(text_preprocessed, text):\n",
        "  #import models and vectorizers\n",
        "  naive_bayes_model = joblib.load('naive_bayes_multinomial_model.pkl')\n",
        "  naive_bayes_vectorizer = joblib.load('naive_bayes_multinomial_vectorizer.pkl')\n",
        "\n",
        "  decision_tree_model = joblib.load('decision_tree_model.pkl')\n",
        "  decision_tree_vectorizer = joblib.load('decision_tree_vectorizer.pkl')\n",
        "\n",
        "  svc_model = joblib.load('SVC_model.pkl')\n",
        "  svc_vectorizer = joblib.load('SVC_vectorizer.pkl')\n",
        "\n",
        "  #pass models text\n",
        "  naive_bayes_prediction = naive_bayes_model.predict(naive_bayes_vectorizer.transform([text_preprocessed]))\n",
        "  decision_tree_prediction = decision_tree_model.predict(decision_tree_vectorizer.transform([text_preprocessed]))\n",
        "  svc_prediction = svc_model.predict(svc_vectorizer.transform([text_preprocessed]))\n",
        "  distilbert_prediction = load_model_and_predict(text)\n",
        "  openai_prediction = openAITest(text)\n",
        "\n",
        "  #determine if the prediction is phishing or safe\n",
        "  phishing_count = 0\n",
        "  safe_count = 0\n",
        "  if naive_bayes_prediction[0] == 1:\n",
        "    print(\"naive bayes phishing\")\n",
        "    phishing_count += 1\n",
        "  else:\n",
        "    print(\"naive bayes safe\")\n",
        "    safe_count += 1\n",
        "  if decision_tree_prediction[0] == 1:\n",
        "    print(\"decision tree phishing\")\n",
        "    phishing_count += 1\n",
        "  else:\n",
        "    print(\"decision tree safe\")\n",
        "    safe_count += 1\n",
        "  if svc_prediction[0] == 1:\n",
        "    print(\"svc phishing\")\n",
        "    phishing_count += 1\n",
        "  else:\n",
        "    print(\"svc safe\")\n",
        "    safe_count += 1\n",
        "  if distilbert_prediction == 1:\n",
        "    print(\"distilbert phishing\")\n",
        "    phishing_count += 1\n",
        "  else:\n",
        "    print(\"distilbert safe\")\n",
        "    safe_count += 1\n",
        "  if openai_prediction == 1:\n",
        "    print(\"openai phishing\")\n",
        "    phishing_count += 1\n",
        "  else:\n",
        "    print(\"openai safe\")\n",
        "    safe_count += 1\n",
        "\n",
        "  if phishing_count > safe_count:\n",
        "    print(\"This email is predicted to be phishing.\")\n",
        "  else:\n",
        "    print(\"This email is predicted to be safe.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  #text = \"get your m 3 ds here - admix articulatory elastomer bogey condescend bohr slough affiance chasm thong dispensable johnsen coven dock hourglass ocean ciliate memphis personify\"\n",
        "  #text = \"re : driscoll ranch # 3 gas pricing and interconnect estimate\"\n",
        "  text = \"\"\n",
        "  text_preprocessed = cleanData(text)\n",
        "\n",
        "  #if the email is empty after preprocessing do not run\n",
        "  if(text_preprocessed == \"\" or text_preprocessed == \" \"):\n",
        "    print(\"invalid input, the email does not have enough information\")\n",
        "  else:\n",
        "    votingModel(str(text_preprocessed), str(text))\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWvQamqNptM5",
        "outputId": "d8602307-d5c8-40d6-bc1b-c7a613f55ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "naive bayes safe\n",
            "decision tree safe\n",
            "svc safe\n",
            "distilbert safe\n",
            "openai safe\n",
            "This email is predicted to be safe.\n"
          ]
        }
      ]
    }
  ]
}